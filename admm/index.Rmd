---
title: "Solving Statistical Optimization Problems with the ADMM Package"
author: "Yixuan Qiu"
output:
  html_document:
    self_contained: no
    theme: flatly
    toc: yes
    toc_depth: 2
---

```{r setup, include=FALSE}
library(knitr)
opts_chunk$set(eval=FALSE, dpi=72)
```

## Introduction

**ADMM** is an R package that utilizes the Alternating Direction Method of Multipliers
(ADMM) algorithm to solve a broad range of statistical optimization problems.
Presently the models that **ADMM** has implemented include:

- Lasso & Elastic Net
- Dantzig Selector
- Least Absolute Deviation
- Basis Pursuit

The core part of **ADMM** is written in efficient C++ code, with the help of
the [Eigen](http://eigen.tuxfamily.org) library and its R wrapper
[RcppEigen](http://cran.r-project.org/web/packages/RcppEigen/index.html).
The computational performance of **ADMM** is comparable to the most cutting-edge
R packages such as [glmnet](http://cran.r-project.org/web/packages/glmnet/index.html),
and outperforms most existing solvers on other models.

The **ADMM** package is especially suitable for large scale problems, in which
an acceptable solution can be obtained in a few iterations for a moderate
precision. It also supports parallel computing using [OpenMP](http://openmp.org)
for even bigger data.

## Installation

Currently **ADMM** can be installed from [GitHub](https://github.com/yixuan/ADMM)
using the [devtools](http://cran.r-project.org/web/packages/devtools/index.html)
package.

```{r}
# install devtools package if not present
if(!require("devtools"))  install.packages("devtools")
library(devtools)
install_github("yixuan/ADMM")
```

**ADMM** relies on extension R packages
[RcppEigen](http://cran.r-project.org/web/packages/RcppEigen/index.html),
[rARPACK](http://cran.r-project.org/web/packages/rARPACK/index.html) and
[ggplot2](http://cran.r-project.org/web/packages/ggplot2/index.html).
The `install_github()` command above will also install these dependencies if required.

## Algorithms

The **ADMM** package is an implementation of the ADMM algorithm on a number of
popular statistical models. The ADMM algorithm solves problems of the form

$$\begin{aligned}
\text{minimize}\quad & f(x)+g(z)\\
\text{subject to}\quad & Ax + Bz = c
\end{aligned}$$

where $x$, $z$ are vectors, $A$ and $B$ are matrices of suitable dimensions,
and $f$, $g$ are convex functions.

A wide range of statistical optimization problems can be written in this form,
including the ones that this package has implemented. 

ADMM algorithm can be expressed in the following iterative update equations:

$$\begin{align}
x^{k+1} & :=\underset{x}{\arg\min}\left(f(x)+\frac{\rho}{2}\Vert Ax+Bz^{k}-c+y^{k}/\rho\Vert_{2}^{2}\right)\\
z^{k+1} & :=\underset{z}{\arg\min}\left(g(z)+\frac{\rho}{2}\Vert Ax^{k+1}+Bz-c+y^{k}/\rho\Vert_{2}^{2}\right)\\
y^{k+1} & :=y^{k}+\rho(Ax^{k+1}+Bz^{k+1}-c)
\end{align}$$

where $\rho>0$ is the step size parameter. More details about this algorithm
can be found in the reference <...>.

## Quick Start

This section provides the basic usage and flavors of the **ADMM** package.
We will go through some simple examples to illustrate the common use of
**ADMM** functions. More details will be given in the next section.

We first generate some synthetic random data for the Lasso, Elastic Net and
Dantzig Selector models:

```{r eval=TRUE}
set.seed(123)
n = 100
p = 20
nonzero = 5
b = matrix(c(runif(nonzero), rep(0, p - nonzero)))
x = matrix(rnorm(n * p, mean = 1.2, sd = 2), n, p)
y = 5 + x %*% b + rnorm(n)
```

Unlike most other model building functions in R and extension packages, **ADMM**
makes use of the Reference Class infrastructure in R to build and fit models,
so that the syntax is in an Object-Oriented Programming (OOP) style. The typical
way to fit an model can be expressed in the following steps:

1. Call a particular model function to create a "model object".
2. Set necessary parameters and options through member functions of this model
object.
3. Actually run the estimation procedure by calling the model fitting member
function.
4. Conduct additional tasks, such as plotting and prediction.

For the first step, functions calls are quite straightforward: simply provide
the data matrix and response vector as arguments. The following code
creates three model objects of the corresponding types.

```{r eval=TRUE}
library(ADMM)
mod1 = admm_lasso(x, y)
mod2 = admm_enet(x, y)
mod3 = admm_dantzig(x, y)
```

Note that at this stage no real computation has been conducted. The model objects
are simply descriptions of the model setting, which can be modified by calling
a number of member functions:

```{r eval=TRUE}
mod2$penalty(alpha = 0.3)
mod2$opts(maxit = 1000)

mod3$penalty(lambda_min_ratio = 0.01)
```

The commands above set the $\alpha$ parameter in the Elastic Net model to be 0.3,
limit the number of iterations to be 1000, and adjust the tuning parameter
sequence in the Dantzig Selector model.

After setting necessary parameters and options, models could be fitted by the
`$fit()` member function. This is where the actual computation is done.

```{r eval=TRUE}
fit1 = mod1$fit()
fit2 = mod2$fit()
fit3 = mod3$fit()
```

Now the calculated $\beta$ vectors are contained in the `beta` field of the
obtained results. Solution path plots can also be created by further calling
the `$plot()` member function on the result objects.

```{r eval=TRUE, out.width="300px", fig.show='hold'}
print(fit1$beta[1:6, 1:6])
library(ggplot2)
fit1$plot() %+% ggtitle("Solution Path for Lasso")
fit2$plot() %+% ggtitle("Solution Path for Enet")
fit3$plot() %+% ggtitle("Solution Path for Dantzig Selector")
```

An appealing feature of the **ADMM** package is that most model building
functions are "chainable", in the sense that one member function call
can be followed by another. Hence the commands above can be simplified into
some shorter code:

```{r}
admm_lasso(x, y)$fit()$plot()

mod2 = admm_enet(x, y)$penalty(alpha = 0.3)$opts(maxit = 1000)
mod2$fit()$plot()

fit3 = admm_dantzig(x, y)$penalty(lambda_min_ratio = 0.01)$fit()
fit3$plot()
```

## Models And References

The **ADMM** package has implemented a number of popular models in statistics and
machine learning using the algorithm introduced above. This section summarizes
the usage of various functions in **ADMM** that are related to specific models.

### Lasso

Lasso is a popular variable selection technique in high dimensional
regression analysis, which tries to find the coefficient vector $\beta$
that minimizes

$$\frac{1}{2n}\Vert y-X\beta\Vert_2^2+\lambda\Vert\beta\Vert_1$$

Here $n$ is the sample size and $\lambda$ is the regularization
parameter that controls the sparseness of $\beta$.

A Lasso model can be built and fitted using the functions below:

- `admm_lasso(x, y, intercept, standardize, ...)`
    - This creates a model object of class `ADMM_Lasso`. It does not conduct
    the computation, but rather stores the parameters and settings of this model.
    - `x`: Predictor data matrix
    - `y`: Response Vector
    - `intercept`: Whether to fit an intercept in the model. Default is `TRUE`.
    - `standardize`: Whether to standardize the explanatory variables before
    fitting the model. Default is `TRUE`. Fitted coefficients are always
    returned on the original scale.
- `model$penalty(lambda, nlambda, lambda_min_ratio, ...)`
    - This member function sets the sequence of $\lambda$ parameters to create
    a solution path of the Lasso model. Arguments of this function have similar
    meanings as in the [glmnet](http://cran.r-project.org/web/packages/glmnet/index.html)
    package.
    - `model`: Model object, typically returned by `admm_lasso()`
    - `lambda`, `nlambda`, `lambda_min_ratio`: See `?ADMM::admm_lasso` for details.
- `model$parallel(nthread)`
    - This member function sets the number of threads for parallel computing.
    - `model`: Model object
    - `nthread`: Number of threads to be used
- `model$opts(maxit, eps_abs, eps_rel, rho_ratio)`
    - This member function sets options that relate to the ADMM algorithm
    - `model`: Model object
    - `maxit`: Maximum number of iterations
    - `eps_abs`: Absolute tolerance parameter
    - `eps_rel`: Relative tolerance parameter
    - `rho_ratio`: Step size parameter in the ADMM algorithm
- `model$fit()`
    - This member function starts the computation to fit the model, and returns
    an object with fields and member functions:
    - `lambda`: The sequence of $\lambda$ to build the solution path
    - `beta`: A sparse matrix containing the estimated coefficient vectors,
    each column for one $\lambda$. Intercepts are contained in the first row.
    - `niter`: Number of ADMM iterations
    - `$plot()`: Member function to create plots

The simplest syntax to obtain the model fitting result is to call

```{r}
res = admm_lasso(x, y)$fit()
```

While most member functions of class `ADMM_Lasso` return the model object itself,
it is possible (and recommended) to call a sequence of member functions in a
"chain style":

```{r}
res = admm_lasso(x, y)$penalty(nlambda = 50)$parallel(2)$opts(maxit = 100)$fit()
```

which is equivalent to

```{r}
model = admm_lasso(x, y)
model$penalty(nlambda = 50)
model$parallel(2)
model$opts(maxit = 100)
res = model$fit()
```

Clearly, the chain style syntax is more concise and intuitive.

Once the model is fitted, we can create a solution path plot by calling the
`$plot()` member function of `res`:

```{r}
res$plot()
```

### Elastic Net

### Dantzig Selector

### Least Absolute Deviation

### Basis Pursuit

## Additional Examples