<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">

<head>

<meta charset="utf-8">
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />

<meta name="author" content="Yixuan Qiu" />


<title>Solving Statistical Optimization Problems with the ADMM Package</title>

<script src="index_files/jquery-1.11.0/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="index_files/bootstrap-3.3.1/css/flatly.min.css" rel="stylesheet" />
<script src="index_files/bootstrap-3.3.1/js/bootstrap.min.js"></script>
<script src="index_files/bootstrap-3.3.1/shim/html5shiv.min.js"></script>
<script src="index_files/bootstrap-3.3.1/shim/respond.min.js"></script>

<style type="text/css">code{white-space: pre;}</style>
<link rel="stylesheet"
      href="index_files/highlight/default.css"
      type="text/css" />
<script src="index_files/highlight/highlight.js"></script>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>
<script type="text/javascript">
if (window.hljs && document.readyState && document.readyState === "complete") {
   window.setTimeout(function() {
      hljs.initHighlighting();
   }, 0);
}
</script>



</head>

<body>

<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img { 
  max-width:100%; 
  height: auto; 
}
</style>
<div class="container-fluid main-container">


<div id="header">
<h1 class="title">Solving Statistical Optimization Problems with the ADMM Package</h1>
<h4 class="author"><em>Yixuan Qiu</em></h4>
</div>

<div id="TOC">
<ul>
<li><a href="#introduction">Introduction</a></li>
<li><a href="#installation">Installation</a></li>
<li><a href="#algorithms">Algorithms</a></li>
<li><a href="#quick-start">Quick Start</a></li>
<li><a href="#models-and-references">Models And References</a></li>
<li><a href="#additional-examples">Additional Examples</a></li>
</ul>
</div>

<div id="introduction" class="section level2">
<h2>Introduction</h2>
<p><strong>ADMM</strong> is an R package that utilizes the Alternating Direction Method of Multipliers (ADMM) algorithm to solve a broad range of statistical optimization problems. Presently the models that <strong>ADMM</strong> has implemented include:</p>
<ul>
<li>Lasso &amp; Elastic Net</li>
<li>Dantzig Selector</li>
<li>Least Absolute Deviation</li>
<li>Basis Pursuit</li>
</ul>
<p>The core part of <strong>ADMM</strong> is written in efficient C++ code, with the help of the <a href="http://eigen.tuxfamily.org">Eigen</a> library and its R wrapper <a href="http://cran.r-project.org/web/packages/RcppEigen/index.html">RcppEigen</a>. The computational performance of <strong>ADMM</strong> is comparable to the most cutting-edge R packages such as <a href="http://cran.r-project.org/web/packages/glmnet/index.html">glmnet</a>, and outperforms most existing solvers on other models.</p>
<p>The <strong>ADMM</strong> package is especially suitable for large scale problems, in which an acceptable solution can be obtained in a few iterations for a moderate precision. It also supports parallel computing using <a href="http://openmp.org">OpenMP</a> for even bigger data.</p>
</div>
<div id="installation" class="section level2">
<h2>Installation</h2>
<p>Currently <strong>ADMM</strong> can be installed from <a href="https://github.com/yixuan/ADMM">GitHub</a> using the <a href="http://cran.r-project.org/web/packages/devtools/index.html">devtools</a> package.</p>
<pre class="r"><code># install devtools package if not present
if(!require(&quot;devtools&quot;))  install.packages(&quot;devtools&quot;)
library(devtools)
install_github(&quot;yixuan/ADMM&quot;)</code></pre>
<p><strong>ADMM</strong> relies on extension R packages <a href="http://cran.r-project.org/web/packages/RcppEigen/index.html">RcppEigen</a>, <a href="http://cran.r-project.org/web/packages/rARPACK/index.html">rARPACK</a> and <a href="http://cran.r-project.org/web/packages/ggplot2/index.html">ggplot2</a>. The <code>install_github()</code> command above will also install these dependencies if required.</p>
</div>
<div id="algorithms" class="section level2">
<h2>Algorithms</h2>
<p>The <strong>ADMM</strong> package is an implementation of the ADMM algorithm on a number of popular statistical models. The ADMM algorithm solves problems of the form</p>
<p><span class="math">\[\begin{aligned}
\text{minimize}\quad &amp; f(x)+g(z)\\
\text{subject to}\quad &amp; Ax + Bz = c
\end{aligned}\]</span></p>
<p>where <span class="math">\(x\)</span>, <span class="math">\(z\)</span> are vectors, <span class="math">\(A\)</span> and <span class="math">\(B\)</span> are matrices of suitable dimensions, and <span class="math">\(f\)</span>, <span class="math">\(g\)</span> are convex functions.</p>
<p>A wide range of statistical optimization problems can be written in this form, including the ones that this package has implemented.</p>
<p>ADMM algorithm can be expressed in the following iterative update equations:</p>
<p><span class="math">\[\begin{align}
x^{k+1} &amp; :=\underset{x}{\arg\min}\left(f(x)+\frac{\rho}{2}\Vert Ax+Bz^{k}-c+y^{k}/\rho\Vert_{2}^{2}\right)\\
z^{k+1} &amp; :=\underset{z}{\arg\min}\left(g(z)+\frac{\rho}{2}\Vert Ax^{k+1}+Bz-c+y^{k}/\rho\Vert_{2}^{2}\right)\\
y^{k+1} &amp; :=y^{k}+\rho(Ax^{k+1}+Bz^{k+1}-c)
\end{align}\]</span></p>
<p>where <span class="math">\(\rho&gt;0\)</span> is the step size parameter. More details about this algorithm can be found in the reference &lt;…&gt;.</p>
</div>
<div id="quick-start" class="section level2">
<h2>Quick Start</h2>
<p>This section provides the basic usage and flavors of the <strong>ADMM</strong> package. We will go through some simple examples to illustrate the common use of <strong>ADMM</strong> functions. More details will be given in the next section.</p>
<p>We first generate some synthetic random data for the Lasso, Elastic Net and Dantzig Selector models:</p>
<pre class="r"><code>set.seed(123)
n = 100
p = 20
nonzero = 5
b = matrix(c(runif(nonzero), rep(0, p - nonzero)))
x = matrix(rnorm(n * p, mean = 1.2, sd = 2), n, p)
y = 5 + x %*% b + rnorm(n)</code></pre>
<p>Unlike most other model building functions in R and extension packages, <strong>ADMM</strong> makes use of the Reference Class infrastructure in R to build and fit models, so that the syntax is in an Object-Oriented Programming (OOP) style. The typical way to fit an model can be expressed in the following steps:</p>
<ol style="list-style-type: decimal">
<li>Call a particular model function to create a “model object”.</li>
<li>Set necessary parameters and options through member functions of this model object.</li>
<li>Actually run the estimation procedure by calling the model fitting member function.</li>
<li>Conduct additional tasks, such as plotting and prediction.</li>
</ol>
<p>For the first step, functions calls are quite straightforward: simply provide the data matrix and response vector as arguments. The following code creates three model objects of the corresponding types.</p>
<pre class="r"><code>library(ADMM)
mod1 = admm_lasso(x, y)
mod2 = admm_enet(x, y)
mod3 = admm_dantzig(x, y)</code></pre>
<p>Note that at this stage no real computation has been conducted. The model objects are simply descriptions of the model setting, which can be modified by calling a number of member functions:</p>
<pre class="r"><code>mod2$penalty(alpha = 0.3)
mod2$opts(maxit = 1000)

mod3$penalty(lambda_min_ratio = 0.01)</code></pre>
<p>The commands above set the <span class="math">\(\alpha\)</span> parameter in the Elastic Net model to be 0.3, limit the number of iterations to be 1000, and adjust the tuning parameter sequence in the Dantzig Selector model.</p>
<p>After setting necessary parameters and options, models could be fitted by the <code>$fit()</code> member function. This is where the actual computation is done.</p>
<pre class="r"><code>fit1 = mod1$fit()
fit2 = mod2$fit()
fit3 = mod3$fit()</code></pre>
<p>Now the calculated <span class="math">\(\beta\)</span> vectors are contained in the <code>beta</code> field of the obtained results. Solution path plots can also be created by further calling the <code>$plot()</code> member function on the result objects.</p>
<pre class="r"><code>print(fit1$beta[1:6, 1:6])</code></pre>
<pre><code>## 6 x 6 sparse Matrix of class &quot;dgCMatrix&quot;
##                                                                      
## [1,] 8.641706e+00 8.53032039 8.3720347 8.2277785 8.0963507 7.93507155
## [2,] .            .          .         .         .         .         
## [3,] .            .          .         .         .         0.03183425
## [4,] .            .          .         .         .         .         
## [5,] .            0.02119865 0.1009311 0.1736284 0.2398610 0.30166664
## [6,] 3.405897e-06 0.09894514 0.1801963 0.2542077 0.3216373 0.38159870</code></pre>
<pre class="r"><code>library(ggplot2)
fit1$plot() %+% ggtitle(&quot;Solution Path for Lasso&quot;)
fit2$plot() %+% ggtitle(&quot;Solution Path for Enet&quot;)
fit3$plot() %+% ggtitle(&quot;Solution Path for Dantzig Selector&quot;)</code></pre>
<p><img src="index_files/figure-html/unnamed-chunk-6-1.png" title="" alt="" width="300px" /><img src="index_files/figure-html/unnamed-chunk-6-2.png" title="" alt="" width="300px" /><img src="index_files/figure-html/unnamed-chunk-6-3.png" title="" alt="" width="300px" /></p>
<p>An appealing feature of the <strong>ADMM</strong> package is that most model building functions are “chainable”, in the sense that one member function call can be followed by another. Hence the commands above can be simplified into some shorter code:</p>
<pre class="r"><code>admm_lasso(x, y)$fit()$plot()

mod2 = admm_enet(x, y)$penalty(alpha = 0.3)$opts(maxit = 1000)
mod2$fit()$plot()

fit3 = admm_dantzig(x, y)$penalty(lambda_min_ratio = 0.01)$fit()
fit3$plot()</code></pre>
</div>
<div id="models-and-references" class="section level2">
<h2>Models And References</h2>
<p>The <strong>ADMM</strong> package has implemented a number of popular models in statistics and machine learning using the algorithm introduced above. This section summarizes the usage of various functions in <strong>ADMM</strong> that are related to specific models.</p>
<div id="lasso" class="section level3">
<h3>Lasso</h3>
<p>Lasso is a popular variable selection technique in high dimensional regression analysis, which tries to find the coefficient vector <span class="math">\(\beta\)</span> that minimizes</p>
<p><span class="math">\[\frac{1}{2n}\Vert y-X\beta\Vert_2^2+\lambda\Vert\beta\Vert_1\]</span></p>
<p>Here <span class="math">\(n\)</span> is the sample size and <span class="math">\(\lambda\)</span> is the regularization parameter that controls the sparseness of <span class="math">\(\beta\)</span>.</p>
<p>A Lasso model can be fit using the functions below:</p>
<ul>
<li><code>admm_lasso(x, y, intercept, standardize, ...)</code>
<ul>
<li>This creates a model object of class <code>ADMM_Lasso</code>. It does not conduct the computation, but rather stores the parameters and settings of this model.</li>
<li><code>x</code>: Predictor data matrix</li>
<li><code>y</code>: Response Vector</li>
<li><code>intercept</code>: Whether to fit an intercept in the model. Default is <code>TRUE</code>.</li>
<li><code>standardize</code>: Whether to standardize the explanatory variables before fitting the model. Default is <code>TRUE</code>. Fitted coefficients are always returned on the original scale.</li>
</ul></li>
<li><code>model$penalty(lambda, nlambda, lambda_min_ratio, ...)</code>
<ul>
<li>This member function sets the sequence of <span class="math">\(\lambda\)</span> parameters to create a solution path of the Lasso model. Arguments of this function have similar meanings as in the <a href="http://cran.r-project.org/web/packages/glmnet/index.html">glmnet</a> package.</li>
<li><code>model</code>: Model object, typically returned by <code>admm_lasso()</code></li>
<li><code>lambda</code>, <code>nlambda</code> etc.: See <code>?admm_lasso</code> for details.</li>
</ul></li>
<li><code>model$parallel(nthread)</code>
<ul>
<li>This member function sets the number of threads for parallel computing.</li>
<li><code>model</code>: Model object</li>
<li><code>nthread</code>: Number of threads to be used</li>
</ul></li>
<li><code>model$opts(maxit, eps_abs, eps_rel, rho_ratio)</code>
<ul>
<li>This member function sets options that relate to the ADMM algorithm</li>
<li><code>model</code>: Model object</li>
<li><code>maxit</code>: Maximum number of iterations</li>
<li><code>eps_abs</code>: Absolute tolerance parameter</li>
<li><code>eps_rel</code>: Relative tolerance parameter</li>
<li><code>rho_ratio</code>: Step size parameter in the ADMM algorithm</li>
</ul></li>
<li><code>model$fit()</code>
<ul>
<li>This member function starts the computation to fit the model, and returns an object with fields:</li>
<li><code>lambda</code>: The sequence of <span class="math">\(\lambda\)</span> to build the solution path</li>
<li><code>beta</code>: A sparse matrix containing the estimated coefficient vectors, each column for one <span class="math">\(\lambda\)</span>. Intercepts are contained in the first row.</li>
<li><code>niter</code>: Number of ADMM iterations</li>
<li><code>$plot()</code>: Member function to create plots</li>
</ul></li>
</ul>
<p>The simplest syntax to obtain the model fitting result is to call</p>
<pre class="r"><code>res = admm_lasso(x, y)$fit()</code></pre>
<p>While most member functions of class <code>ADMM_Lasso</code> return the model object itself, it is possible (and recommended) to call a sequence of member functions in a “chain style”:</p>
<pre class="r"><code>res = admm_lasso(x, y)$penalty(nlambda = 50)$parallel(2)$opts(maxit = 100)$fit()</code></pre>
<p>which is equivalent to</p>
<pre class="r"><code>model = admm_lasso(x, y)
model$penalty(nlambda = 50)
model$parallel(2)
model$opts(maxit = 100)
res = model$fit()</code></pre>
<p>Clearly, the chain style syntax is more concise and intuitive.</p>
<p>Once the model is fitted, we can create a solution path plot by calling the <code>$plot()</code> member function of <code>res</code>:</p>
<pre class="r"><code>res$plot()</code></pre>
</div>
<div id="elastic-net" class="section level3">
<h3>Elastic Net</h3>
</div>
<div id="dantzig-selector" class="section level3">
<h3>Dantzig Selector</h3>
</div>
<div id="least-absolute-deviation" class="section level3">
<h3>Least Absolute Deviation</h3>
</div>
<div id="basis-pursuit" class="section level3">
<h3>Basis Pursuit</h3>
</div>
</div>
<div id="additional-examples" class="section level2">
<h2>Additional Examples</h2>
</div>


</div>

<script>

// add bootstrap table styles to pandoc tables
$(document).ready(function () {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
});

</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
